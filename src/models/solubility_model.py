# src/models/solubility_model.py
import joblib
import pandas as pd
import os
import time

# --- 1. –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –≤—Å–µ —Ä–µ–≥—Ä–µ—Å—Å–æ—Ä—ã, –∫–æ—Ç–æ—Ä—ã–µ —Ö–æ—Ç–∏–º –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å ---
from sklearn.linear_model import LinearRegression, Lasso, Ridge
from sklearn.neighbors import KNeighborsRegressor
from sklearn.svm import SVR
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from xgboost import XGBRegressor
from lightgbm import LGBMRegressor

from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline


def train_and_evaluate_models(df):
    """
    –û–±—É—á–∞–µ—Ç –±–æ–ª—å—à–æ–π –Ω–∞–±–æ—Ä —Ä–µ–≥—Ä–µ—Å—Å–æ—Ä–æ–≤, —Å—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –∏—Ö –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –ª—É—á—à—É—é –º–æ–¥–µ–ª—å.
    """
    print("üì• –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è...")

    # –†–∞–∑–¥–µ–ª—è–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –Ω–∞ —á–∏—Å–ª–æ–≤—ã–µ –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
    categorical_features = ['solvent']
    numerical_features = ['temperature_k', 'mol_weight', 'logp', 'tpsa', 'h_donors', 'h_acceptors']

    X = df[categorical_features + numerical_features].dropna()
    y = df.loc[X.index]['log_s']

    print(f"üßÆ –ò—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: {categorical_features + numerical_features}")

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # --- 2. –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–±—â–∏–π –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä —Å –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ–º! ---
    # OneHotEncoder –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π –∏ StandardScaler –¥–ª—è —á–∏—Å–µ–ª.
    # –≠—Ç–æ –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û –¥–ª—è –ª–∏–Ω–µ–π–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π, SVR –∏ KNN.
    preprocessor = ColumnTransformer(
        transformers=[
            ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features),
            ('scaler', StandardScaler(), numerical_features)
        ],
        remainder='passthrough'  # –ù–∞ —Å–ª—É—á–∞–π, –µ—Å–ª–∏ –ø–æ—è–≤—è—Ç—Å—è –¥—Ä—É–≥–∏–µ —Å—Ç–æ–ª–±—Ü—ã
    )

    # --- 3. –û–ø—Ä–µ–¥–µ–ª—è–µ–º –±–æ–ª—å—à–æ–π —Å–ª–æ–≤–∞—Ä—å –º–æ–¥–µ–ª–µ–π –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è ---
    models = {
        "LinearRegression": LinearRegression(),
        "Lasso": Lasso(random_state=42),
        "Ridge": Ridge(random_state=42),
        "KNeighborsRegressor": KNeighborsRegressor(),
        "SVR": SVR(),
        "RandomForest": RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),
        "GradientBoosting": GradientBoostingRegressor(n_estimators=100, random_state=42),
        "XGBoost": XGBRegressor(n_estimators=100, random_state=42, n_jobs=-1),
        "LightGBM": LGBMRegressor(n_estimators=100, random_state=42, n_jobs=-1, verbose=-1)
    }

    results = []
    best_mae = float('inf')
    best_model_pipeline = None
    best_model_name = ""

    # --- 4. –û–±—É—á–∞–µ–º –∏ –æ—Ü–µ–Ω–∏–≤–∞–µ–º –∫–∞–∂–¥—É—é –º–æ–¥–µ–ª—å –≤ —Ü–∏–∫–ª–µ ---
    for name, model in models.items():
        print(f"\n--- –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏: {name} ---")
        start_time = time.time()

        pipeline = Pipeline([
            ('preprocessor', preprocessor),
            ('regressor', model)
        ])

        pipeline.fit(X_train, y_train)
        y_pred = pipeline.predict(X_test)

        end_time = time.time()
        training_time = end_time - start_time

        mae = mean_absolute_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)

        results.append({
            "–ú–æ–¥–µ–ª—å": name,
            "MAE": mae,
            "R¬≤": r2,
            "–í—Ä–µ–º—è (—Å–µ–∫)": training_time
        })

        print(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è {name}: MAE = {mae:.3f}, R¬≤ = {r2:.3f}, –í—Ä–µ–º—è = {training_time:.2f} —Å–µ–∫")

        if mae < best_mae:
            best_mae = mae
            best_model_pipeline = pipeline
            best_model_name = name

    # --- 5. –í—ã–≤–æ–¥–∏–º –∫—Ä–∞—Å–∏–≤—É—é –∏—Ç–æ–≥–æ–≤—É—é —Ç–∞–±–ª–∏—Ü—É ---
    results_df = pd.DataFrame(results).sort_values(by="MAE").reset_index(drop=True)
    print("\n\n--- üìä –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ---")
    print(results_df.to_string())

    # --- 6. –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –ª—É—á—à—É—é –º–æ–¥–µ–ª—å ---
    print(f"\nüèÜ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å –ø–æ –º–µ—Ç—Ä–∏–∫–µ MAE: {best_model_name} (MAE = {best_mae:.3f})")

    os.makedirs("models", exist_ok=True)
    model_path = "models/best_model.pkl"
    joblib.dump(best_model_pipeline, model_path)
    print(f"üíæ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {model_path}")

    return best_model_pipeline


def predict_optimal_conditions(smiles, temp_range=(273, 350), solvents=None):
    """
    –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –æ—Å—Ç–∞–µ—Ç—Å—è –ë–ï–ó –ò–ó–ú–ï–ù–ï–ù–ò–ô. –û–Ω–∞ –ø—Ä–æ—Å—Ç–æ –∑–∞–≥—Ä—É–∂–∞–µ—Ç
    –ª—É—á—à—É—é –º–æ–¥–µ–ª—å, –∫–∞–∫–æ–π –±—ã –æ–Ω–∞ –Ω–∏ –±—ã–ª–∞.
    """
    if solvents is None:
        solvents = ["O", "CCO", "CC(C)O", "C1CCOC1", "CS(C)=O"]

    model_path = "models/best_model.pkl"
    try:
        model = joblib.load(model_path)
    except FileNotFoundError:
        return f"‚ùå –§–∞–π–ª –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ '{model_path}' –Ω–µ –Ω–∞–π–¥–µ–Ω. –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ –æ–±—É—á–µ–Ω–∏–µ."
    except Exception as e:
        return f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}"

    from src.features.smiles_featurizer import calculate_molecular_features
    features = calculate_molecular_features(smiles)

    if pd.isna(features[0]) or any(pd.isna(f) for f in features):
        return "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å SMILES –∏–ª–∏ —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä—ã."

    mol_weight, logp, tpsa, h_donors, h_acceptors, _ = features
    print(f"‚úÖ –î–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä—ã —Ä–∞—Å—Å—á–∏—Ç–∞–Ω—ã.")

    best_solvent = None
    best_temp = 0
    max_solubility = -float('inf')
    results = []

    print("üîç –ü–æ–∏—Å–∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö —É—Å–ª–æ–≤–∏–π...")
    for solvent_smiles in solvents:
        for temp in range(temp_range[0], temp_range[1] + 1, 10):
            X = pd.DataFrame([{
                'temperature_k': temp,
                'solvent': solvent_smiles,
                'mol_weight': mol_weight,
                'logp': logp,
                'tpsa': tpsa,
                'h_donors': h_donors,
                'h_acceptors': h_acceptors
            }])
            try:
                pred = model.predict(X)[0]
                results.append({
                    'solvent_smiles': solvent_smiles,
                    'temp_k': temp,
                    'temp_c': temp - 273.15,
                    'log_s': pred
                })

                if pred > max_solubility:
                    max_solubility = pred
                    best_solvent = solvent_smiles
                    best_temp = temp
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è {solvent_smiles} –ø—Ä–∏ {temp}K: {e}")
                continue

    if best_solvent is None:
        return "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ —É—Å–ª–æ–≤–∏—è."

    result = {
        'smiles': smiles,
        'best_solvent_smiles': best_solvent,
        'best_temperature_k': best_temp,
        'best_temperature_c': best_temp - 273.15,
        'predicted_logS': max_solubility,
        'predicted_solubility_mol_per_l': 10 ** max_solubility,
    }

    results.sort(key=lambda x: x['log_s'], reverse=True)
    result['top_5_conditions'] = results[:5]

    print("‚úÖ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
    return result